{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datascience.util\n",
    "import datascience.tables as Table\n",
    "import numpy as np\n",
    "result = Table.Table()\n",
    "k = [1,5,9,15]\n",
    "train_result = []\n",
    "validate_result = []\n",
    "test_result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 1:\n",
    "\n",
    "Training Error:  0.0\n",
    "\n",
    "Validation Error:  0.082\n",
    "\n",
    "Test Error:  0.094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 5:\n",
    "\n",
    "Training Error:  0.0565\n",
    "\n",
    "Validation Error:  0.099\n",
    "\n",
    "Test Error:  0.099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 9:\n",
    "\n",
    "Training Error:  0.0705\n",
    "\n",
    "Validation Error:  0.101\n",
    "\n",
    "Test Error:  0.097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 15:\n",
    "\n",
    "Training Error:  0.092\n",
    "\n",
    "Validation Error:  0.107\n",
    "\n",
    "Test Error:  0.116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier of k = 1 performs the best on validation data.\n",
    "\n",
    "The test error of this classifier is 0.094."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 1:\n",
    "\n",
    "Training Error:  0.0\n",
    "\n",
    "Validation Error:  0.32\n",
    "\n",
    "Test Error:  0.314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 5:\n",
    "\n",
    "Training Error:  0.1975\n",
    "\n",
    "Validation Error:  0.3\n",
    "\n",
    "Test Error:  0.301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 9:\n",
    "\n",
    "Training Error:  0.234\n",
    "\n",
    "Validation Error:  0.295\n",
    "\n",
    "Test Error:  0.286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 15:\n",
    "\n",
    "Training Error:  0.2585\n",
    "\n",
    "Validation Error:  0.288\n",
    "\n",
    "Test Error:  0.306"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier of k = 15 performs the best on validation data.\n",
    "\n",
    "The test error of this classifier is 0.306.\n",
    "\n",
    "The classification accuracy decreases as affected by projection.\n",
    "\n",
    "The program runs faster after projection as dimensions of matrices are reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(\"./pa1train.txt\", \"r\")\n",
    "test_data = open(\"./pa1test.txt\", \"r\")\n",
    "validate_data = open(\"./pa1validate.txt\", \"r\")\n",
    "projection_data = open(\"./projection.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = [each_line.strip() for each_line in train_data]\n",
    "train_data = [[int(s) for s in each_line.strip().split()] for each_line in train_data]\n",
    "\n",
    "train = [i[:784] for i in train_data]\n",
    "train_label = [i[-1] for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = [each_line.strip() for each_line in test_data]\n",
    "test_data = [[int(s) for s in each_line.strip().split()] for each_line in test_data]\n",
    "\n",
    "test = [i[:784] for i in test_data]\n",
    "test_label = [i[-1] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_data = [each_line.strip() for each_line in validate_data]\n",
    "validate_data = [[int(s) for s in each_line.strip().split()] for each_line in validate_data]\n",
    "\n",
    "validate = [i[:784] for i in validate_data]\n",
    "validate_label = [i[-1] for i in validate_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "projection_data = [each_line.strip() for each_line in projection_data]\n",
    "projection = []\n",
    "\n",
    "for each_line in projection_data:\n",
    "    block = []\n",
    "    split = each_line.split()\n",
    "    for i in range(20):\n",
    "        block.append(float(split[i]))\n",
    "    projection.append(block)\n",
    "projection = np.array(projection)\n",
    "projection = projection.transpose().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def select(data):\n",
    "    record = dict()\n",
    "    for x in data:\n",
    "        if x not in record:\n",
    "            record[x] = 0\n",
    "        record[x] += 1\n",
    "    most = max([record[x] for x in record])\n",
    "    output = [x for x in record if record[x] == most]        \n",
    "    return random.choice(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(x, y):\n",
    "    return sum([(x[i]-y[i])**2 for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_dist(data, train_data):\n",
    "    result = []\n",
    "    for i in range(len(data)):\n",
    "        each = []\n",
    "        for j in range(len(train_data)):\n",
    "            each.append((get_dist(data[i], train_data[j]), j))\n",
    "        block = []\n",
    "        for x in sorted(each):\n",
    "            block.append(x[1])\n",
    "        result.append(block)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(k):    \n",
    "    labels = []\n",
    "    for i in train_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    train_error = sum(train_label[i] != labels[i] for i in range(len(train_label)))/len(train_label)\n",
    "    print(\"Training Error: \", train_error)\n",
    "    \n",
    "    labels = []\n",
    "    for i in validate_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    validate_error = sum(validate_label[i] != labels[i] for i in range(len(validate_label)))/len(validate_label)\n",
    "    print(\"Validation Error: \", validate_error)\n",
    "    \n",
    "    labels = []\n",
    "    for i in test_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    test_error = sum(test_label[i] != labels[i] for i in range(len(test_label)))/len(test_label)\n",
    "    print(\"Test Error: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = data_dist(train, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dist = data_dist(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dist = data_dist(validate, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5a888d7e6073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-40a472a8616b>\u001b[0m in \u001b[0;36mKNN\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dist' is not defined"
     ]
    }
   ],
   "source": [
    "KNN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.0565\n",
      "Validation Error:  0.099\n",
      "Test Error:  0.099\n"
     ]
    }
   ],
   "source": [
    "KNN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.0705\n",
      "Validation Error:  0.101\n",
      "Test Error:  0.097\n"
     ]
    }
   ],
   "source": [
    "KNN(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.092\n",
      "Validation Error:  0.107\n",
      "Test Error:  0.116\n"
     ]
    }
   ],
   "source": [
    "KNN(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.042\n",
      "Validation Error:  0.093\n",
      "Test Error:  0.085\n"
     ]
    }
   ],
   "source": [
    "KNN(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    result = []\n",
    "    for i in range(len(x)):\n",
    "        result.append(x[i] + y[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x, y):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result += (x[i] * y[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(m, x):\n",
    "    return [m * x[i] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(mat):\n",
    "    i =1 \n",
    "    result = []\n",
    "    for x in mat:\n",
    "        block = [0] * len(x)\n",
    "        for y in projection:\n",
    "            block = add(block, mul(dot(x, y)/sum(np.array(y)**2), y))\n",
    "        result.append(block)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_KNN(k):\n",
    "    labels = []\n",
    "    for i in proj_train_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    train_error = sum(train_label[i] != labels[i] for i in range(len(train_label)))/len(train_label)\n",
    "    print(\"Training Error: \", train_error)\n",
    "    \n",
    "    labels = []\n",
    "    for i in proj_validate_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    validate_error = sum(validate_label[i] != labels[i] for i in range(len(validate_label)))/len(validate_label)\n",
    "    print(\"Validation Error: \", validate_error)\n",
    "    \n",
    "    labels = []\n",
    "    for i in proj_test_dist:\n",
    "        block = []\n",
    "        for j in i[:k]:\n",
    "            block.append(train_label[j])\n",
    "        labels.append(block)\n",
    "    temp = labels\n",
    "    labels = []\n",
    "    for x in temp:\n",
    "        labels.append(select(x))\n",
    "    test_error = sum(test_label[i] != labels[i] for i in range(len(test_label)))/len(test_label)\n",
    "    print(\"Test Error: \", test_error)\n",
    "    train_result.append(train_error)\n",
    "    validate_result.append(validate_error)\n",
    "    test_result.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_train = proj(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_test = proj(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_validate = proj(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_train_dist = data_dist(proj_train, proj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_test_dist = data_dist(proj_test, proj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_validate_dist = data_dist(proj_validate, proj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.0\n",
      "Validation Error:  0.32\n",
      "Test Error:  0.314\n"
     ]
    }
   ],
   "source": [
    "proj_KNN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.1975\n",
      "Validation Error:  0.3\n",
      "Test Error:  0.301\n"
     ]
    }
   ],
   "source": [
    "proj_KNN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.234\n",
      "Validation Error:  0.295\n",
      "Test Error:  0.286\n"
     ]
    }
   ],
   "source": [
    "proj_KNN(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.2585\n",
      "Validation Error:  0.288\n",
      "Test Error:  0.306\n"
     ]
    }
   ],
   "source": [
    "proj_KNN(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:  0.157\n",
      "Validation Error:  0.32\n",
      "Test Error:  0.303\n"
     ]
    }
   ],
   "source": [
    "proj_KNN(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
